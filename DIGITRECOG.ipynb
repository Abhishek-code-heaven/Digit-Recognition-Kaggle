{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\abhis\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\abhis\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\abhis\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\abhis\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\abhis\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\abhis\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "def init_model():\n",
    "    \n",
    "    ###  Model Definition\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5, 5), padding='Valid', activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='Same', activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(5, 5), padding='Valid', activation='relu'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='Same', activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(519, activation=\"relu\"))  # [[521,0.9962,70],[519,0.9969,51]\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-3), metrics=[\"accuracy\"])\n",
    "\n",
    "    annealer = ReduceLROnPlateau(monitor='val_acc', patience=1, verbose=2, factor=0.5, min_lr=0.0000001) #patience=2\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        rotation_range=10,\n",
    "        zoom_range=0.1,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=False)  # , preprocessing_function=random_add_or_erase_spot)\n",
    "\n",
    "    return model, annealer, datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import lib\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "print(train.shape)\n",
    "\n",
    "#Prepare dataset\n",
    "y = train[\"label\"]\n",
    "X = train.drop(\"label\", axis = 1)\n",
    "print(y.value_counts().to_dict())\n",
    "y = to_categorical(y, num_classes = 10)\n",
    "del train\n",
    "\n",
    "X = X / 255.0\n",
    "X = X.values.reshape(-1,28,28,1)\n",
    "\n",
    "# Shuffle Split Train and Test from original dataset\n",
    "seed=2\n",
    "train_index, valid_index = ShuffleSplit(n_splits=1,\n",
    "                                        train_size=0.9,\n",
    "                                        test_size=None,\n",
    "                                        random_state=seed).split(X).__next__()\n",
    "x_train = X[train_index]\n",
    "Y_train = y[train_index]\n",
    "x_test = X[valid_index]\n",
    "Y_test = y[valid_index]\n",
    "\n",
    "# Parameters\n",
    "epochs = 30\n",
    "batch_size = 64\n",
    "validation_steps = 10000\n",
    "\n",
    "# initialize Model, Annealer and Datagen\n",
    "model, annealer, datagen = init_model()\n",
    "\n",
    "# Start training\n",
    "train_generator = datagen.flow(x_train, Y_train, batch_size=batch_size)\n",
    "test_generator = datagen.flow(x_test, Y_test, batch_size=batch_size)\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=x_train.shape[0]//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=test_generator,\n",
    "                    validation_steps=validation_steps//batch_size,\n",
    "                    callbacks=[annealer])\n",
    "\n",
    "score = model.evaluate(x_test, Y_test)\n",
    "print('Test accuracy: ', score[1])\n",
    "\n",
    "# Saving Model for future API\n",
    "model.save('Digits-1.3.0.h5')\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "## Model predict\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "print(test.shape)\n",
    "test = test / 255\n",
    "test = test.values.reshape(-1, 28, 28, 1)\n",
    "p = np.argmax(model.predict(test), axis=1)\n",
    "\n",
    "print('Base model scores:')\n",
    "valid_loss, valid_acc = model.evaluate(x_test, Y_test, verbose=0)\n",
    "valid_p = np.argmax(model.predict(x_test), axis=1)\n",
    "target = np.argmax(Y_test, axis=1)\n",
    "cm = confusion_matrix(target, valid_p)\n",
    "print(cm)\n",
    "\n",
    "## Preparing file for submission\n",
    "submission = pd.DataFrame(pd.Series(range(1, p.shape[0] + 1), name='ImageId'))\n",
    "submission['Label'] = p\n",
    "filename=\"keras-cnn-{0}.csv\".format(str(int(score[1]*10000)))\n",
    "submission.to_csv(filename, index=False)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"Elapsed time: {0}\".format(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Using cached Keras-2.3.1-py2.py3-none-any.whl (377 kB)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\abhis\\appdata\\roaming\\python\\python37\\site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from keras) (5.3)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\abhis\\appdata\\roaming\\python\\python37\\site-packages (from keras) (1.14.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\abhis\\appdata\\roaming\\python\\python37\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\abhis\\appdata\\roaming\\python\\python37\\site-packages (from keras) (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\abhis\\appdata\\roaming\\python\\python37\\site-packages (from keras) (1.18.4)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-413d596884f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# summarize history for accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lib in c:\\programdata\\anaconda3\\lib\\site-packages (3.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting labelImg\n",
      "  Using cached https://files.pythonhosted.org/packages/91/04/3a48958976f3f82a1d21cdfcd26c87f8c753275a88578b9a9e4ca3a18a93/labelImg-1.8.3-py2.py3-none-any.whl\n",
      "Collecting pyqt5 (from labelImg)\n",
      "  Using cached https://files.pythonhosted.org/packages/d7/8e/5fa1dd8095728fa754e96633d4c97e0283fb0be5ab3a0a25f7df054deff1/PyQt5-5.14.2-5.14.2-cp35.cp36.cp37.cp38-none-win_amd64.whl\n",
      "Requirement already satisfied: lxml in c:\\programdata\\anaconda3\\lib\\site-packages (from labelImg) (4.4.1)\n",
      "Requirement already satisfied: PyQt5-sip<13,>=12.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyqt5->labelImg) (12.7.2)\n",
      "Installing collected packages: pyqt5, labelImg\n",
      "Successfully installed labelImg-1.8.3 pyqt5-5.14.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: spyder 3.3.6 requires pyqtwebengine<5.13; python_version >= \"3\", which is not installed.\n",
      "ERROR: spyder 3.3.6 has requirement pyqt5<5.13; python_version >= \"3\", but you'll have pyqt5 5.14.2 which is incompatible.\n",
      "  WARNING: The scripts pylupdate5.exe, pyrcc5.exe and pyuic5.exe are installed in 'C:\\Users\\abhis\\AppData\\Roaming\\Python\\Python37\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script labelImg.exe is installed in 'C:\\Users\\abhis\\AppData\\Roaming\\Python\\Python37\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install --user labelImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting model\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Could not find a version that satisfies the requirement model (from versions: none)\n",
      "ERROR: No matching distribution found for model\n"
     ]
    }
   ],
   "source": [
    "pip install model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n",
      "Base model scores:\n",
      "[[408   0   0   0   0   0   3   0   0   0]\n",
      " [  0 482   0   0   0   0   0   2   1   0]\n",
      " [  0   0 403   0   0   0   0   0   0   0]\n",
      " [  0   0   0 415   0   0   0   0   3   0]\n",
      " [  0   0   0   0 459   0   1   0   0   1]\n",
      " [  0   0   0   1   0 367   2   0   2   0]\n",
      " [  0   0   0   0   2   0 410   0   1   0]\n",
      " [  0   0   0   0   0   0   0 446   0   0]\n",
      " [  0   0   0   0   2   0   0   0 379   1]\n",
      " [  0   0   0   0   1   0   0   2   1 405]]\n",
      "Elapsed time: 00:38:42\n"
     ]
    }
   ],
   "source": [
    "## Model predict\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "print(test.shape)\n",
    "test = test / 255\n",
    "test = test.values.reshape(-1, 28, 28, 1)\n",
    "p = np.argmax(model.predict(test), axis=1)\n",
    "\n",
    "print('Base model scores:')\n",
    "valid_loss, valid_acc = model.evaluate(x_test, Y_test, verbose=0)\n",
    "valid_p = np.argmax(model.predict(x_test), axis=1)\n",
    "target = np.argmax(Y_test, axis=1)\n",
    "cm = confusion_matrix(target, valid_p)\n",
    "print(cm)\n",
    "\n",
    "## Preparing file for submission\n",
    "submission = pd.DataFrame(pd.Series(range(1, p.shape[0] + 1), name='ImageId'))\n",
    "submission['Label'] = p\n",
    "filename=\"keras-cnn-{0}.csv\".format(str(int(score[1]*10000)))\n",
    "submission.to_csv(filename, index=False)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"Elapsed time: {0}\".format(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
